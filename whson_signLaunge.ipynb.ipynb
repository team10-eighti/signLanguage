{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import gradio as gr\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
    "\n",
    "# Azure OpenAI 및 Cognitive Search 설정\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://team10-eighti.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://team10-eighti-search.search.windows.net\")\n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"wnalAsW6FqKRHIR6S3sUZGzNH28Lf3sBOS2ubCZsZxAzSeA205k3\")\n",
    "search_index = os.getenv(\"SEARCH_INDEX_NAME\", \"sign-index\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1BajXTI5Mp0tKrs46XFGuOWjSPXKzOZSKy8e6R3qha1SVQ4lz1PFJQQJ99ALACYeBjFXJ3w3AAABACOGgPvw\")\n",
    "\n",
    "# Azure Speech Service 설정 (한국어 음성 출력)\n",
    "speech_key = os.getenv(\"AZURE_SPEECH_KEY\", \"AwjVcsBAkpnrMNwkobsgJ4SSroO1GkAztrEIYp1JuMTcuKcfDR3wJQQJ99ALACYeBjFXJ3w3AAAYACOGZMDc\")\n",
    "speech_region = os.getenv(\"AZURE_SPEECH_REGION\", \"eastus\")\n",
    "speech_config = SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_synthesis_language = \"ko-KR\"  # 한국어 설정\n",
    "speech_config.speech_synthesis_voice_name = \"ko-KR-SunHiNeural\"  # 한국어 음성\n",
    "speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Azure OpenAI 클라이언트 초기화\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# 채팅 함수 정의\n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    try:\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{search_endpoint}\",\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{search_key}\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 응답 추출 및 대화 기록 업데이트\n",
    "        assistant_reply = completion.choices[0].message.content  # 속성 접근 방식으로 수정\n",
    "        chat_history.append((user_input, assistant_reply))  # 튜플 형태로 추가\n",
    "\n",
    "        # Azure Speech Service로 응답 읽기 (텍스트를 한국어 음성으로 변환)\n",
    "        speech_synthesizer.speak_text_async(assistant_reply)\n",
    "\n",
    "        return chat_history, chat_history\n",
    "\n",
    "    except Exception as e:\n",
    "        return [(\"Error\", str(e))], chat_history\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Azure OpenAI + Cognitive Search + Speech 기반 수화 챗봇\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "    clear_button = gr.Button(\"Clear Chat\")\n",
    "    \n",
    "    # 대화 기록 저장\n",
    "    state = gr.State([])\n",
    "\n",
    "    # 이벤트 연결\n",
    "    user_input.submit(chat_with_openai, [user_input, state], [chatbot, state])\n",
    "    clear_button.click(lambda: [], None, chatbot)\n",
    "\n",
    "# 실행\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import gradio as gr\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
    "import re\n",
    "\n",
    "# Azure OpenAI 및 Cognitive Search 설정\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://team10-eighti.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://team10-eighti-search.search.windows.net\")\n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"wnalAsW6FqKRHIR6S3sUZGzNH28Lf3sBOS2ubCZsZxAzSeA205k3\")\n",
    "search_index = os.getenv(\"SEARCH_INDEX_NAME\", \"sign-index\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1BajXTI5Mp0tKrs46XFGuOWjSPXKzOZSKy8e6R3qha1SVQ4lz1PFJQQJ99ALACYeBjFXJ3w3AAABACOGgPvw\")\n",
    "\n",
    "# Azure Speech Service 설정 (한국어 음성 출력)\n",
    "speech_key = os.getenv(\"AZURE_SPEECH_KEY\", \"AwjVcsBAkpnrMNwkobsgJ4SSroO1GkAztrEIYp1JuMTcuKcfDR3wJQQJ99ALACYeBjFXJ3w3AAAYACOGZMDc\")\n",
    "speech_region = os.getenv(\"AZURE_SPEECH_REGION\", \"eastus\")\n",
    "speech_config = SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_synthesis_language = \"ko-KR\"  # 한국어 설정\n",
    "speech_config.speech_synthesis_voice_name = \"ko-KR-SunHiNeural\"  # 한국어 음성\n",
    "speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Azure OpenAI 클라이언트 초기화\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# 링크 추출 함수\n",
    "def extract_links(text):\n",
    "    image_links = []\n",
    "    video_links = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        if line.endswith(\".jpg\") or line.endswith(\".png\"):\n",
    "            image_links.append(line.strip())\n",
    "        elif line.endswith(\".mp4\"):\n",
    "            video_links.append(line.strip())\n",
    "    return image_links, video_links\n",
    "\n",
    "\n",
    "# 채팅 함수 정의\n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    try:\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{search_endpoint}\",\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{search_key}\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 응답 추출 및 대화 기록 업데이트\n",
    "        assistant_reply = completion.choices[0].message.context['citations'][0]['content']  # 속성 접근 방식으로 수정\n",
    "        \n",
    "        # 이미지 및 동영상 링크 추출\n",
    "        image_links, video_links = extract_links(assistant_reply)\n",
    "        \n",
    "        chat_history.append((user_input, assistant_reply))  # 튜플 형태로 추가\n",
    "\n",
    "        # 음성 출력 (링크 제외 텍스트만 읽기)\n",
    "        speech_text = re.sub(r\"http\\S+\", \"\", assistant_reply).strip()\n",
    "        speech_synthesizer.speak_text_async(speech_text)\n",
    "\n",
    "        # 반환: 대화 기록, 첫 번째 이미지 링크, 첫 번째 동영상 링크\n",
    "        return chat_history, image_links[0] if image_links else None, video_links[0] if video_links else None\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        return [(\"Error\", str(e))], chat_history\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Azure OpenAI + Cognitive Search + Speech 기반 수화 챗봇\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "            clear_button = gr.Button(\"Clear Chat\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            video_display = gr.Video(label=\"관련 동영상\")\n",
    "            image_display = gr.Image(label=\"관련 이미지\")\n",
    "            \n",
    "    state = gr.State([])\n",
    "\n",
    "    # 이벤트 연결\n",
    "    user_input.submit(chat_with_openai, [user_input, state], [chatbot, image_display, video_display])\n",
    "    clear_button.click(lambda: ([], None, None), None, [chatbot, image_display, video_display])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#재빈님 코드드\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import gradio as gr\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
    "\n",
    "# Azure OpenAI 및 Cognitive Search 설정\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://team10-eighti.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://team10-eighti-search.search.windows.net\")\n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"wnalAsW6FqKRHIR6S3sUZGzNH28Lf3sBOS2ubCZsZxAzSeA205k3\")\n",
    "search_index = os.getenv(\"SEARCH_INDEX_NAME\", \"sign-index\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1BajXTI5Mp0tKrs46XFGuOWjSPXKzOZSKy8e6R3qha1SVQ4lz1PFJQQJ99ALACYeBjFXJ3w3AAABACOGgPvw\")\n",
    "\n",
    "# Azure Speech Service 설정 (한국어 음성 출력)\n",
    "speech_key = os.getenv(\"AZURE_SPEECH_KEY\", \"AwjVcsBAkpnrMNwkobsgJ4SSroO1GkAztrEIYp1JuMTcuKcfDR3wJQQJ99ALACYeBjFXJ3w3AAAYACOGZMDc\")\n",
    "speech_region = os.getenv(\"AZURE_SPEECH_REGION\", \"eastus\")\n",
    "speech_config = SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_synthesis_language = \"ko-KR\"  # 한국어 설정\n",
    "speech_config.speech_synthesis_voice_name = \"ko-KR-SunHiNeural\"  # 한국어 음성\n",
    "speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Azure OpenAI 클라이언트 초기화\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# 채팅 함수 정의\n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    try:\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{search_endpoint}\",\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{search_key}\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 응답 추출 및 대화 기록 업데이트\n",
    "        assistant_reply = completion.choices[0].message.content.replace(' [doc1]', '').strip()  # 속성 접근 방식으로 수정\n",
    "        chat_history.append((user_input, assistant_reply))  # 튜플 형태로 추가\n",
    "\n",
    "        citations = completion.choices[0].message.context['citations'][0]['content'].split('\\n')\n",
    "        video_url = citations[-2]\n",
    "        image_urls = citations[-3].split(' ')   # 이미지 URL이 여러 개일 수 있음\n",
    "\n",
    "        # Azure Speech Service로 응답 읽기 (텍스트를 한국어 음성으로 변환)\n",
    "        # speech_synthesizer.speak_text_async(assistant_reply)\n",
    "\n",
    "        return chat_history, chat_history, video_url, image_urls\n",
    "\n",
    "    except Exception as e:\n",
    "        return [(\"Error\", str(e))], chat_history\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"# Azure OpenAI + Cognitive Search + Speech 기반 수화 챗봇\")\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "            clear_button = gr.Button(\"Clear Chat\")\n",
    "        with gr.Column():\n",
    "            video_display = gr.Video(label=\"수어 영상\")\n",
    "            image_display = gr.Gallery(label=\"수어 이미지\", columns=3)\n",
    "\n",
    "    # 대화 기록 저장\n",
    "    state = gr.State([])\n",
    "\n",
    "    # 이벤트 연결    \n",
    "    user_input.submit(chat_with_openai, [user_input, state], [chatbot, state, video_display, image_display])\n",
    "    clear_button.click(lambda: [], None, chatbot)\n",
    "    \n",
    "# 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\components\\chatbot.py:237: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\blocks.py:1776: UserWarning: A function (chat_with_openai) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
      "    Output components:\n",
      "        [chatbot, image, video, row]\n",
      "    Output values returned:\n",
      "        [[('수박', '과일\\n두 손을 구부려 손끝이 위로 향하게 하여 입 앞에서 좌우로 움직인다.\\nhttp://sldict.korean.go.kr/multimedia/multimedia_files/convert/20151221/232087/IMG000226279_700X466.jpg\\nhttp://sldict.korean.go.kr/multimedia/multimedia_files/convert/20191011/626519/MOV000253031_700X466.mp4\\n수박')], \"http://sldict.korean.go.kr/multimedia/multimedia_files/convert/20151221/232087/IMG000226279_700X466.jpg\", \"http://sldict.korean.go.kr/multimedia/multimedia_files/convert/20191011/626519/MOV000253031_700X466.mp4\", {'__type__': 'update', 'visible': False}, {'__type__': 'update', 'visible': False}]\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\blocks.py:1776: UserWarning: A function (chat_with_openai) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
      "    Output components:\n",
      "        [chatbot, image, video, row]\n",
      "    Output values returned:\n",
      "        [[('수박', '과일\\n두 손을 구부려 손끝이 위로 향하게 하여 입 앞에서 좌우로 움직인다.\\nhttp://sldict.korean.go.kr/multimedia/multimedia_files/convert/20151221/232087/IMG000226279_700X466.jpg\\nhttp://sldict.korean.go.kr/multimedia/multimedia_files/convert/20191011/626519/MOV000253031_700X466.mp4\\n수박'), ('Error', 'Error: list index out of range')], None, None, {'__type__': 'update', 'visible': True}, {'__type__': 'update', 'visible': True}]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from openai import AzureOpenAI\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Azure OpenAI 및 Cognitive Search 설정\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://team10-eighti.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://team10-eighti-search.search.windows.net\")\n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"wnalAsW6FqKRHIR6S3sUZGzNH28Lf3sBOS2ubCZsZxAzSeA205k3\")\n",
    "search_index = os.getenv(\"SEARCH_INDEX_NAME\", \"sign-index\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1BajXTI5Mp0tKrs46XFGuOWjSPXKzOZSKy8e6R3qha1SVQ4lz1PFJQQJ99ALACYeBjFXJ3w3AAABACOGgPvw\")\n",
    "\n",
    "# Speech Service 설정 (한국어 음성 출력)\n",
    "speech_key = os.getenv(\"AZURE_SPEECH_KEY\", \"AwjVcsBAkpnrMNwkobsgJ4SSroO1GkAztrEIYp1JuMTcuKcfDR3wJQQJ99ALACYeBjFXJ3w3AAAYACOGZMDc\")\n",
    "speech_region = os.getenv(\"AZURE_SPEECH_REGION\", \"eastus\")\n",
    "speech_config = SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_synthesis_language = \"ko-KR\"\n",
    "speech_config.speech_synthesis_voice_name = \"ko-KR-SunHiNeural\"\n",
    "speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Azure Custom Vision 설정\n",
    "custom_vision_endpoint = \"https://team10eighticustomvision-prediction.cognitiveservices.azure.com/\"\n",
    "prediction_key = \"9FRZbiwBubFIcSZ1k88tCTCskOAZwMMAMvnFLuVJ26tlU0V0fsqjJQQJ99ALACYeBjFXJ3w3AAAIACOGOj1S\"\n",
    "project_id = \"4218ecac-688a-422b-9e14-2726b938f67c\"\n",
    "published_name = \"Iteration8\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(endpoint=custom_vision_endpoint, credentials=credentials)\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# 링크 추출 함수\n",
    "def extract_links(text):\n",
    "    image_links = []\n",
    "    video_links = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        if line.endswith(\".jpg\") or line.endswith(\".png\"):\n",
    "            image_links.append(line.strip())\n",
    "        elif line.endswith(\".mp4\"):\n",
    "            video_links.append(line.strip())\n",
    "    return image_links, video_links\n",
    "\n",
    "# Azure Custom Vision: 프레임 처리 함수\n",
    "def process_frame(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "\n",
    "    # Convert frame to PIL Image for Azure API\n",
    "    pil_image = Image.fromarray(frame)\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    pil_image.save(img_byte_arr, format='PNG')\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "    try:\n",
    "        # Get predictions from Azure Custom Vision\n",
    "        results = predictor.detect_image(project_id, published_name, img_byte_arr)\n",
    "        \n",
    "        # Draw bounding boxes on the frame\n",
    "        for prediction in results.predictions:\n",
    "            if prediction.probability > 0.5:  # Threshold for displaying predictions\n",
    "                box = prediction.bounding_box\n",
    "                left = int(box.left * frame.shape[1])\n",
    "                top = int(box.top * frame.shape[0])\n",
    "                width = int(box.width * frame.shape[1])\n",
    "                height = int(box.height * frame.shape[0])\n",
    "                \n",
    "                # Draw rectangle and label on the frame\n",
    "                cv2.rectangle(frame, (left, top), (left + width, top + height), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, f\"{prediction.tag_name}: {prediction.probability:.2f}\",\n",
    "                            (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return frame\n",
    "\n",
    "# 채팅 함수 정의\n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    try:\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": search_endpoint,\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": search_key\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 응답 추출 및 대화 기록 업데이트\n",
    "        assistant_reply = completion.choices[0].message.context['citations'][0]['content']\n",
    "\n",
    "        # 이미지 및 동영상 링크 추출\n",
    "        image_links, video_links = extract_links(assistant_reply)\n",
    "\n",
    "        chat_history.append((user_input, assistant_reply))\n",
    "\n",
    "        # 음성 출력 (링크 제외 텍스트만 읽기)\n",
    "        speech_text = re.sub(r\"http\\S+\", \"\", assistant_reply).strip()\n",
    "        speech_synthesizer.speak_text_async(speech_text)\n",
    "\n",
    "        # Webcam Input과 Custom Vision Output 숨김 상태 유지 (정상 작동 시)\n",
    "        return chat_history, image_links[0] if image_links else None, video_links[0] if video_links else None, gr.update(visible=False), gr.update(visible=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error: {str(e)}\"\n",
    "        chat_history.append((\"Error\", error_message))\n",
    "\n",
    "        # Webcam Input과 Custom Vision Output 표시 (오류 발생 시)\n",
    "        return chat_history, None, None, gr.update(visible=True), gr.update(visible=True)\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Azure OpenAI + Cognitive Search + Speech 기반 수화 챗봇\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "            clear_button_chatbot = gr.Button(\"Clear Chatbot\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            image_display_chatbot = gr.Image(label=\"관련 이미지\")\n",
    "            video_display_chatbot = gr.Video(label=\"관련 동영상\")\n",
    "\n",
    "    with gr.Row(visible=False) as custom_vision_section:  # 기본적으로 숨김 처리된 섹션\n",
    "        webcam_input_custom_vision = gr.Image(sources=\"webcam\", streaming=True, mirror_webcam=True, label=\"Webcam Input\")\n",
    "        output_custom_vision = gr.Image(label=\"Custom Vision Output\")\n",
    "\n",
    "    state_chatbot = gr.State([])\n",
    "\n",
    "    # 이벤트 연결: 챗봇 기능\n",
    "    user_input.submit(chat_with_openai,\n",
    "                      [user_input, state_chatbot],\n",
    "                      [chatbot, image_display_chatbot, video_display_chatbot, custom_vision_section])\n",
    "\n",
    "    clear_button_chatbot.click(lambda: ([], None, None), None,\n",
    "                               [chatbot, image_display_chatbot, video_display_chatbot])\n",
    "\n",
    "    # 이벤트 연결: Custom Vision 기능 (실시간 분석)\n",
    "    webcam_input_custom_vision.stream(process_frame,\n",
    "                                      inputs=webcam_input_custom_vision,\n",
    "                                      outputs=output_custom_vision)\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
