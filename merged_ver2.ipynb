{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-cognitiveservices-vision-customvision\n",
    "# !pip install azure-cognitiveservices-speech\n",
    "# !pip install msrest\n",
    "# !pip install openai\n",
    "# !pip install gradio\n",
    "# !pip install opencv-python\n",
    "# !pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\components\\chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import unicodedata\n",
    "from PIL import Image\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Azure OpenAI 및 Cognitive Search 설정\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://team10-eighti.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://team10-eighti-search.search.windows.net\")\n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"wnalAsW6FqKRHIR6S3sUZGzNH28Lf3sBOS2ubCZsZxAzSeA205k3\")\n",
    "search_index = os.getenv(\"SEARCH_INDEX_NAME\", \"sign-index\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1BajXTI5Mp0tKrs46XFGuOWjSPXKzOZSKy8e6R3qha1SVQ4lz1PFJQQJ99ALACYeBjFXJ3w3AAABACOGgPvw\")\n",
    "\n",
    "# Azure Speech Service 설정 (한국어 음성 출력)\n",
    "speech_key = os.getenv(\"AZURE_SPEECH_KEY\", \"AwjVcsBAkpnrMNwkobsgJ4SSroO1GkAztrEIYp1JuMTcuKcfDR3wJQQJ99ALACYeBjFXJ3w3AAAYACOGZMDc\")\n",
    "speech_region = os.getenv(\"AZURE_SPEECH_REGION\", \"eastus\")\n",
    "speech_config = SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_synthesis_language = \"ko-KR\"  # 한국어 설정\n",
    "speech_config.speech_synthesis_voice_name = \"ko-KR-SunHiNeural\"  # 한국어 음성\n",
    "speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Azure OpenAI 클라이언트 초기화\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# Azure CustomVision 초기화\n",
    "CUSTOMVISION_ENDPOINT = \"https://team10eighticustomvision-prediction.cognitiveservices.azure.com/\"\n",
    "PREDICTION_KEY = \"9FRZbiwBubFIcSZ1k88tCTCskOAZwMMAMvnFLuVJ26tlU0V0fsqjJQQJ99ALACYeBjFXJ3w3AAAIACOGOj1S\"\n",
    "PROJECT_ID = \"4218ecac-688a-422b-9e14-2726b938f67c\"\n",
    "PUBLISHED_NAME = \"Iteration8\"\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(endpoint=CUSTOMVISION_ENDPOINT, credentials=credentials)\n",
    "\n",
    "################# 자음/모음 분리 함수 #################\n",
    "def split_hangul(word):\n",
    "    initial_consonants = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    medial_vowels = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "    final_consonants = ['', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "    separated = []\n",
    "    for char in word:\n",
    "        if '가' <= char <= '힣':\n",
    "            code = ord(char) - ord('가')\n",
    "            initial = code // (21 * 28)\n",
    "            medial = (code % (21 * 28)) // 28\n",
    "            final = code % 28\n",
    "            separated.append(initial_consonants[initial])\n",
    "            separated.append(medial_vowels[medial])\n",
    "            if final_consonants[final]:\n",
    "                separated.append(final_consonants[final])\n",
    "        else:\n",
    "            separated.append(char)\n",
    "    return separated\n",
    "\n",
    "# 역딕셔너리 생성 (값 -> 키 변환용)\n",
    "hangul_dict = {\"Giyeok\": \"ㄱ\", \"Nieun\": \"ㄴ\", \"Digeut\": \"ㄷ\", \"Rieul\": \"ㄹ\", \"Mieum\": \"ㅁ\", \"Bieup\": \"ㅂ\", \"Siot\": \"ㅅ\",\n",
    "               \"Ieung\": \"ㅇ\", \"Jieut\": \"ㅈ\", \"Chieut\": \"ㅊ\", \"Kieuk\": \"ㅋ\", \"Tieut\": \"ㅌ\", \"Pieup\": \"ㅍ\", \"Hieut\": \"ㅎ\",\n",
    "               \"A\": \"ㅏ\", \"Ya\": \"ㅑ\", \"Eo\": \"ㅓ\", \"Yeo\": \"ㅕ\", \"O\": \"ㅗ\", \"Yo\": \"ㅛ\", \"U\": \"ㅜ\", \"Yu\": \"ㅠ\", \"Eu\": \"ㅡ\",\n",
    "               \"Yi\": \"ㅣ\", \"Ae\": \"ㅐ\", \"Yae\": \"ㅒ\", \"E\": \"ㅔ\", \"Ye\": \"ㅖ\", \"Oe\": \"ㅚ\", \"Wi\": \"ㅟ\", \"Ui\": \"ㅢ\"}\n",
    "reverse_hangul_dict = {value: key for key, value in hangul_dict.items()}\n",
    "\n",
    "def display_images(word):\n",
    "    separated_word = split_hangul(word)\n",
    "    result = [reverse_hangul_dict.get(jamo, \"\") for jamo in separated_word if jamo in reverse_hangul_dict]\n",
    "\n",
    "    image_folder = \"Images/Basic\"  # 이미지 폴더 경로\n",
    "    image_paths = []\n",
    "\n",
    "    for tag in result:\n",
    "        image_path = os.path.join(image_folder, f\"{tag}.jpg\")\n",
    "        if os.path.exists(image_path):\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def generate_gallery(word):\n",
    "    images = display_images(word)\n",
    "    return images\n",
    "\n",
    "\n",
    "################# CUSTOM VISION #################\n",
    "def draw_boxes(image, predictions):\n",
    "    \"\"\"가장 확률이 높은 객체만 경계 상자를 그리도록 수정\"\"\"\n",
    "    img = image.copy()\n",
    "\n",
    "    # 예측 결과 중 확률이 가장 높은 하나를 선택\n",
    "    if predictions:\n",
    "        highest_prediction = max(predictions, key=lambda p: p.probability)\n",
    "\n",
    "        # 확률이 0.5 이상인 객체만 선택\n",
    "        if highest_prediction.probability > 0.5:\n",
    "            color = (255, 0, 0)  # 경계 상자 색상 (빨간색)\n",
    "            box = highest_prediction.bounding_box\n",
    "            left = int(box.left * img.shape[1])\n",
    "            top = int(box.top * img.shape[0])\n",
    "            width = int(box.width * img.shape[1])\n",
    "            height = int(box.height * img.shape[0])\n",
    "\n",
    "            # 경계 상자 그리기\n",
    "            cv2.rectangle(img,\n",
    "                          (left, top),\n",
    "                          (left + width, top + height),\n",
    "                          color,\n",
    "                          2)\n",
    "\n",
    "            # 라벨과 확률 텍스트 추가\n",
    "            label = f\"{highest_prediction.tag_name}: {highest_prediction.probability:.2f}\"\n",
    "            cv2.putText(img,\n",
    "                        label,\n",
    "                        (left, top - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        color,\n",
    "                        2)\n",
    "\n",
    "    return img\n",
    "\n",
    "def process_frame(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "\n",
    "    # Convert frame to PIL Image\n",
    "    pil_image = Image.fromarray(frame)\n",
    "\n",
    "    # Save to bytes for Azure API\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    pil_image.save(img_byte_arr, format='PNG')\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "    try:\n",
    "        # Get predictions from Azure Custom Vision\n",
    "        results = predictor.detect_image(PROJECT_ID, PUBLISHED_NAME, img_byte_arr)\n",
    "\n",
    "        # Draw boxes on frame\n",
    "        annotated_frame = draw_boxes(frame, results.predictions)\n",
    "\n",
    "        return annotated_frame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return frame\n",
    "\n",
    "\n",
    "\n",
    "################# CHATBOT #################\n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    try:\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{search_endpoint}\",\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{search_key}\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 응답 추출 및 대화 기록 업데이트\n",
    "        assistant_reply = completion.choices[0].message.content.replace(' [doc1]', '').strip()  # 속성 접근 방식으로 수정\n",
    "        \n",
    "        # 검색 결과 없는 기본 메시지 처리\n",
    "        if \"요청된 정보는 검색된 데이터에서 찾을 수 없습니다. 다른 쿼리나 주제를 시도해 보세요.\" in assistant_reply:\n",
    "            assistant_reply = \"수어로 확인하기 어려운 단어입니다. 지문자로 연습해보세요!\"\n",
    "\n",
    "        chat_history.append((user_input, assistant_reply))  # 튜플 형태로 추가\n",
    "\n",
    "        # 출처와 관련된 내용 확인\n",
    "        try:\n",
    "            citations = completion.choices[0].message.context['citations'][0]['content'].split('\\n')\n",
    "            video_url = citations[-2]\n",
    "            image_urls = citations[-3].split(' ')  # 이미지 URL이 여러 개일 수 있음\n",
    "        except (KeyError, IndexError):\n",
    "            # 출처 정보를 찾을 수 없을 경우 예외 처리\n",
    "            video_url = None\n",
    "            image_urls = []\n",
    "\n",
    "        # Azure Speech Service로 응답 읽기 (텍스트를 한국어 음성으로 변환)\n",
    "        # speech_synthesizer.speak_text_async(assistant_reply)\n",
    "\n",
    "        return chat_history, chat_history, video_url, image_urls\n",
    "\n",
    "    except Exception as e:\n",
    "        # 오류 메시지 대체\n",
    "        fallback_message = \"수어로 확인하기 어려운 단어입니다. 지문자로 연습해보세요!\"\n",
    "        chat_history.append((user_input, fallback_message))\n",
    "        return chat_history, chat_history, None, []\n",
    "\n",
    "\n",
    "# Gradio 인터페이스\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"## Sign Language Chatbot\")\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "            clear_button = gr.Button(\"★ Clear Chat ★\")\n",
    "            with gr.Row():\n",
    "                video_display = gr.Video(label=\"수어 영상\")\n",
    "                image_display = gr.Gallery(label=\"수어 이미지\", columns=3)\n",
    "        with gr.Column():\n",
    "            toggle_button = gr.Button(\"지문자 연습하기!\")\n",
    "\n",
    "            # 버튼 클릭으로 표시/숨기기되는 영역\n",
    "            with gr.Column(visible=False) as customvision_section:\n",
    "                gr.Markdown(\"## 실시간 CustomVision 객체 인식\")\n",
    "                practice_input = gr.Textbox(label=\"단어 입력\", placeholder=\"단어를 입력하세요\")\n",
    "                practice_gallery = gr.Gallery(label=\"결과 이미지\", columns=6, rows=1)\n",
    "                webcam_input = gr.Image(sources=\"webcam\", streaming=True, mirror_webcam=True, label=\"Webcam\")\n",
    "                webcam_output = gr.Image(label=\"Detected Objects\")\n",
    "\n",
    "                practice_input.change(generate_gallery, inputs=practice_input, outputs=practice_gallery)\n",
    "\n",
    "\n",
    "    # visible 상태를 관리하기 위한 State\n",
    "    visible_state = gr.State(value=True)\n",
    "\n",
    "    # 대화 기록 저장\n",
    "    state = gr.State([])\n",
    "\n",
    "    # 이벤트 연결\n",
    "    user_input.submit(chat_with_openai, [user_input, state], [chatbot, state, video_display, image_display])\n",
    "    # Clear 버튼 이벤트 연결\n",
    "    clear_button.click(\n",
    "        lambda: ([], []),  # chatbot과 state를 모두 초기화\n",
    "        inputs=None,\n",
    "        outputs=[chatbot, state]  # chatbot과 state 모두 업데이트\n",
    "    )\n",
    "\n",
    "    # 버튼 클릭 이벤트로 영역 토글\n",
    "    toggle_button.click(\n",
    "        lambda visible: (not visible, gr.update(visible=not visible)),  # 현재 visible 상태를 반전\n",
    "        inputs=[visible_state],  # 현재 visible 상태를 입력으로 받음\n",
    "        outputs=[visible_state, customvision_section],  # 상태와 섹션의 visible 업데이트\n",
    "    )\n",
    "\n",
    "    # Custom Vision 웹캠 스트림 설정\n",
    "    webcam_input.stream(process_frame, inputs=webcam_input, outputs=webcam_output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
