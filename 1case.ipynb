{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\Lib\\site-packages\\gradio\\components\\chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\python\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\python\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\python\\Lib\\site-packages\\gradio\\blocks.py\", line 2028, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\python\\Lib\\site-packages\\gradio\\blocks.py\", line 1784, in postprocess_data\n",
      "    self.validate_outputs(block_fn, predictions)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\python\\Lib\\site-packages\\gradio\\blocks.py\", line 1739, in validate_outputs\n",
      "    raise ValueError(\n",
      "ValueError: A  function (chat_with_openai) didn't return enough output values (needed: 4, returned: 2).\n",
      "    Output components:\n",
      "        [chatbot, state, video, gallery]\n",
      "    Output values returned:\n",
      "        [[('Error', 'list index out of range')], [('맥주', '맥주를 수화로 표현하려면 오른손가락 끝을 모아 동그라미를 만든 후, 4개의 손가락이 바깥쪽으로 향하게 하고, 다음으로 5개의 손가락만 펴고 1·2·3·4지를 붙여서 바닥이 바깥쪽으로 향하게 세웁니다.'), ('맥주', '맥주를 수화로 표현하려면, 오른손가락 끝을 모아 동그라미를 만든 다음, 4개의 손가락이 바깥쪽으로 향하게 하고, 그 다음으로 5개의 손가락을 펴서 1·2·3·4지를 붙여 바닥이 바깥쪽으로 향하게 세웁니다.'), ('맥주', '맥주를 수화로 표현하는 방법은 다음과 같습니다. 오른손가락 끝을 모아 동그라미를 만든 후, 4개의 손가락이 바깥쪽으로 향하게 하고, 5개의 손가락을 펴서 1, 2, 3, 4지를 붙여서 바닥이 바깥쪽으로 향하게 세웁니다.'), ('맥주', '맥주를 수화로 표현하는 방법은 다음과 같습니다. 오른손가락 끝을 모아 동그라미를 만든 후, 4개의 손가락이 바깥쪽을 향하게 하고, 5개의 손가락을 펴서 1, 2, 3, 4지를 붙여 바닥이 바깥쪽으로 향하게 세웁니다.'), ('맥주', '맥주를 수화로 표현하는 방법은 오른손가락 끝을 모아 동그라미를 만든 다음, 4개의 손가락이 바깥쪽으로 향하게 하고, 5개의 손가락을 펴서 1, 2, 3, 4지를 붙여서 바닥이 바깥쪽으로 향하게 세우는 것입니다.'), ('설렁탕', '설렁탕을 수화로 표현하는 방법은 다음과 같습니다. 오른쪽 주먹의 1지를 봐서 끝으로 치아를 가리키고, 두 손을 봐서 손바닥이 아래로 향하게 하여 내리면서 손가락을 번갈아 흔든 다음, 왼손을 봐서 손바닥이 위로 오므리고, 그 위에서 손바닥이 위로 향하게 편 오른손을 왼쪽으로 두 바퀴 돌립니다.'), ('가방', '요청된 정보는 검색된 데이터에서 찾을 수 없습니다. 다른 쿼리나 주제를 시도해 보세요.')]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import gradio as gr\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
    "\n",
    "# Azure OpenAI 및 Cognitive Search 설정\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://team10-eighti.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://team10-eighti-search.search.windows.net\")\n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"wnalAsW6FqKRHIR6S3sUZGzNH28Lf3sBOS2ubCZsZxAzSeA205k3\")\n",
    "search_index = os.getenv(\"SEARCH_INDEX_NAME\", \"sign-index\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1BajXTI5Mp0tKrs46XFGuOWjSPXKzOZSKy8e6R3qha1SVQ4lz1PFJQQJ99ALACYeBjFXJ3w3AAABACOGgPvw\")\n",
    "\n",
    "# Azure Speech Service 설정 (한국어 음성 출력)\n",
    "speech_key = os.getenv(\"AZURE_SPEECH_KEY\", \"AwjVcsBAkpnrMNwkobsgJ4SSroO1GkAztrEIYp1JuMTcuKcfDR3wJQQJ99ALACYeBjFXJ3w3AAAYACOGZMDc\")\n",
    "speech_region = os.getenv(\"AZURE_SPEECH_REGION\", \"eastus\")\n",
    "speech_config = SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_synthesis_language = \"ko-KR\"  # 한국어 설정\n",
    "speech_config.speech_synthesis_voice_name = \"ko-KR-SunHiNeural\"  # 한국어 음성\n",
    "speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Azure OpenAI 클라이언트 초기화\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# 채팅 함수 정의\n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    try:\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{search_endpoint}\",\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{search_key}\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 응답 추출 및 대화 기록 업데이트\n",
    "        assistant_reply = completion.choices[0].message.content.replace(' [doc1]', '').strip()  # 속성 접근 방식으로 수정\n",
    "        chat_history.append((user_input, assistant_reply))  # 튜플 형태로 추가\n",
    "\n",
    "        citations = completion.choices[0].message.context['citations'][0]['content'].split('\\n')\n",
    "        video_url = citations[-2]\n",
    "        image_urls = citations[-3].split(' ')   # 이미지 URL이 여러 개일 수 있음\n",
    "\n",
    "        # Azure Speech Service로 응답 읽기 (텍스트를 한국어 음성으로 변환)\n",
    "        # speech_synthesizer.speak_text_async(assistant_reply)\n",
    "\n",
    "        return chat_history, chat_history, video_url, image_urls\n",
    "\n",
    "    except Exception as e:\n",
    "        return [(\"Error\", str(e))], chat_history\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"# Azure OpenAI + Cognitive Search + Speech 기반 수화 챗봇\")\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "            clear_button = gr.Button(\"Clear Chat\")\n",
    "        with gr.Column():\n",
    "            video_display = gr.Video(label=\"수어 영상\")\n",
    "            image_display = gr.Gallery(label=\"수어 이미지\", columns=3)\n",
    "\n",
    "    # 대화 기록 저장\n",
    "    state = gr.State([])\n",
    "\n",
    "    # 이벤트 연결    \n",
    "    user_input.submit(chat_with_openai, [user_input, state], [chatbot, state, video_display, image_display])\n",
    "    clear_button.click(lambda: [], None, chatbot)\n",
    "    \n",
    "# 실행\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
