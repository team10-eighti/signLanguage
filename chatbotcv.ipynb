{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\components\\chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import io\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Custom Vision 설정\n",
    "CUSTOM_VISION_ENDPOINT = \"https://team10eighticustomvision-prediction.cognitiveservices.azure.com/\"\n",
    "CUSTOM_VISION_PREDICTION_KEY = \"9FRZbiwBubFIcSZ1k88tCTCskOAZwMMAMvnFLuVJ26tlU0V0fsqjJQQJ99ALACYeBjFXJ3w3AAAIACOGOj1S\"\n",
    "CUSTOM_VISION_PROJECT_ID = \"4218ecac-688a-422b-9e14-2726b938f67c\"\n",
    "CUSTOM_VISION_PUBLISHED_NAME = \"Iteration8\"\n",
    "\n",
    "# Custom Vision 클라이언트 초기화\n",
    "customvision_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": CUSTOM_VISION_PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(endpoint=CUSTOM_VISION_ENDPOINT, credentials=customvision_credentials)\n",
    "\n",
    "# 자음/모음 분리 함수\n",
    "class HangulSplitter:\n",
    "    def __init__(self):\n",
    "        self.initial_consonants = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "        self.medial_vowels = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "        self.final_consonants = ['', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "    def split_hangul(self, word): # 단어 초성 중성 종성 분리\n",
    "        separated = []\n",
    "        for char in word:\n",
    "            if '가' <= char <= '힣':  # 한글 음절인지 확인\n",
    "                code = ord(char) - ord('가')\n",
    "                initial = code // (21 * 28)   # 초성\n",
    "                medial = (code % (21 * 28)) // 28   # 중성\n",
    "                final = code % 28   # 종성\n",
    "                separated.append({\n",
    "                    'initial': self.initial_consonants[initial],\n",
    "                    'medial': self.medial_vowels[medial],\n",
    "                    'final': self.final_consonants[final] if final != 0 else None\n",
    "                })\n",
    "            else:\n",
    "                separated.append({'initial': char, 'medial': None, 'final': None})\n",
    "        return separated\n",
    "\n",
    "    def create_hangul_images(self, word): # 자모음 이미지 생성\n",
    "        separated = self.split_hangul(word)\n",
    "        images = []\n",
    "        \n",
    "        for char_info in separated:\n",
    "            width, height = 50, 100\n",
    "            img = Image.new('RGB', (width, height), color=(255, 255, 255))\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            if char_info['initial'] is not None:\n",
    "                draw.text((10, 30), char_info['initial'], fill=(0, 0, 0))\n",
    "            if char_info['medial'] is not None:\n",
    "                draw.text((20, 60), char_info['medial'], fill=(0, 0, 0))\n",
    "            if char_info['final'] is not None:\n",
    "                draw.text((30, 90), char_info['final'], fill=(0, 0, 0))\n",
    "\n",
    "            images.append(img)\n",
    "        return images\n",
    "\n",
    "\n",
    "# 실시간 웹캠 \n",
    "def process_frame(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    # PIL 이미지로 변환\n",
    "    pil_image = Image.fromarray(frame)\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    pil_image.save(img_byte_arr, format='PNG')\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "    try:\n",
    "        # Azure Custom Vision 예측\n",
    "        results = predictor.detect_image(CUSTOM_VISION_PROJECT_ID, CUSTOM_VISION_PUBLISHED_NAME, img_byte_arr)\n",
    "        annotated_frame = draw_boxes(frame, results.predictions)\n",
    "        return annotated_frame\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return frame\n",
    "\n",
    "# 이미지에 경계 박스 그리기\n",
    "def draw_boxes(image, predictions):\n",
    "    img = image.copy()\n",
    "    for pred in predictions:\n",
    "        if pred.probability > 0.9:\n",
    "            color = (255, 0, 0)\n",
    "            box = pred.bounding_box\n",
    "            left = int(box.left * img.shape[1])\n",
    "            top = int(box.top * img.shape[0])\n",
    "            width = int(box.width * img.shape[1])\n",
    "            height = int(box.height * img.shape[0])\n",
    "        \n",
    "            # 경계 박스 그리기\n",
    "            cv2.rectangle(img, (left, top), (left + width, top + height), color, 2)\n",
    "            label = f\"{pred.tag_name}: {pred.probability:.2f}\"\n",
    "            cv2.putText(img, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Chatbot \n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    try:\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={  # Azure Search와 관련된 설정\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{search_endpoint}\",\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{search_key}\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        assistant_reply = completion.choices[0].message.content.replace(' [doc1]', '').strip()  # 속성 접근 방식으로 수정\n",
    "        chat_history.append((user_input, assistant_reply))  # 튜플 형태로 추가\n",
    "\n",
    "        citations = completion.choices[0].message.context['citations'][0]['content'].split('\\n')\n",
    "        video_url = citations[-2]\n",
    "        image_urls = citations[-3].split(' ')   # 이미지 URL이 여러 개일 수 있음\n",
    "\n",
    "        # Azure Speech Service로 응답 읽기 (텍스트를 한국어 음성으로 변환)\n",
    "        # speech_synthesizer.speak_text_async(assistant_reply)\n",
    "\n",
    "        return chat_history, chat_history, video_url, image_urls\n",
    "\n",
    "    except Exception as e:\n",
    "        return [(\"Error\", str(e))], chat_history\n",
    "\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            gr.Markdown(\"# Azure OpenAI + Cognitive Search + Speech 기반 수화 챗봇\")\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "            clear_button = gr.Button(\"Clear Chat\")\n",
    "        with gr.Column(scale=2):\n",
    "            video_display = gr.Video(label=\"수어 영상\")\n",
    "            image_display = gr.Gallery(label=\"수어 이미지\", columns=3)\n",
    "\n",
    "    with gr.Row():\n",
    "        toggle_button = gr.Button(\"지문자 입력 시작하기\")\n",
    "\n",
    "        # 버튼 클릭으로 표시/숨기기되는 영역\n",
    "        with gr.Column(visible=False) as customvision_section:\n",
    "            webcam = gr.Video(label=\"Webcam Feed\")\n",
    "            webcam_output = gr.Image(label=\"인식 결과\")\n",
    "\n",
    "        with gr.Column(visible=False) as hangul_section:\n",
    "            word_image_output = gr.Gallery(label=\"단어의 자음/모음 이미지\")\n",
    "\n",
    "    # 대화 기록 저장\n",
    "    visible_state = gr.State(value=False)\n",
    "    state = gr.State([])\n",
    "\n",
    "    # 이벤트 연결    \n",
    "    user_input.submit(chat_with_openai, [user_input, state], [chatbot, state, video_display, image_display])\n",
    "    clear_button.click(lambda: [], None, chatbot)\n",
    "\n",
    "    # 버튼 클릭 시 토글 상태 변경\n",
    "    toggle_button.click(\n",
    "        lambda visible: (not visible, gr.update(visible=not visible), gr.update(visible=True)),\n",
    "        inputs=[visible_state],\n",
    "        outputs=[visible_state, customvision_section, hangul_section],\n",
    "    )\n",
    "\n",
    "    # 웹캠 실시간 처리\n",
    "    webcam.change(process_frame, inputs=webcam, outputs=webcam_output)\n",
    "\n",
    "    # 텍스트 입력 시 자음/모음 이미지 생성\n",
    "    user_input.submit(create_hangul_image, [user_input], word_image_output)\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
