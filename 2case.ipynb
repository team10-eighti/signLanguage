{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-customvision in c:\\python\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\python\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\python\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.1.28)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in c:\\python\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.5.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\python\\lib\\site-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (1.32.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2024.8.30)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\python\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (0.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\python\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.0.0)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\python\\lib\\site-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\김재빈\\appdata\\roaming\\python\\python312\\site-packages (from azure-core>=1.31.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\python\\lib\\site-packages (from azure-core>=1.31.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio_modal in c:\\python\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: gradio<6.0,>=4.0 in c:\\python\\lib\\site-packages (from gradio_modal) (5.4.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.115.4)\n",
      "Requirement already satisfied: ffmpy in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.2 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (1.4.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.26.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (2.1.1)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (3.10.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\김재빈\\appdata\\roaming\\python\\python312\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (2.9.2)\n",
      "Requirement already satisfied: pydub in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.7.1)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.41.2)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\python\\lib\\site-packages (from gradio<6.0,>=4.0->gradio_modal) (0.32.0)\n",
      "Requirement already satisfied: fsspec in c:\\python\\lib\\site-packages (from gradio-client==1.4.2->gradio<6.0,>=4.0->gradio_modal) (2024.10.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\python\\lib\\site-packages (from gradio-client==1.4.2->gradio<6.0,>=4.0->gradio_modal) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python\\lib\\site-packages (from anyio<5.0,>=3.0->gradio<6.0,>=4.0->gradio_modal) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python\\lib\\site-packages (from anyio<5.0,>=3.0->gradio<6.0,>=4.0->gradio_modal) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\python\\lib\\site-packages (from httpx>=0.24.1->gradio<6.0,>=4.0->gradio_modal) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python\\lib\\site-packages (from httpx>=0.24.1->gradio<6.0,>=4.0->gradio_modal) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio<6.0,>=4.0->gradio_modal) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\python\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio<6.0,>=4.0->gradio_modal) (3.16.1)\n",
      "Requirement already satisfied: requests in c:\\python\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio<6.0,>=4.0->gradio_modal) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio<6.0,>=4.0->gradio_modal) (4.66.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\김재빈\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio_modal) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio_modal) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio_modal) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python\\lib\\site-packages (from pydantic>=2.0->gradio<6.0,>=4.0->gradio_modal) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\python\\lib\\site-packages (from pydantic>=2.0->gradio<6.0,>=4.0->gradio_modal) (2.23.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\python\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio_modal) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\python\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio_modal) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\python\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio_modal) (13.9.3)\n",
      "Requirement already satisfied: colorama in c:\\python\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio_modal) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\김재빈\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio<6.0,>=4.0->gradio_modal) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio_modal) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\김재빈\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio_modal) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio<6.0,>=4.0->gradio_modal) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio<6.0,>=4.0->gradio_modal) (2.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->gradio_modal) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gradio_modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\Lib\\site-packages\\gradio\\components\\chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7886\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7886/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\Lib\\site-packages\\gradio\\blocks.py:1751: UserWarning: A function (stop_speech) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
      "    Output components:\n",
      "        []\n",
      "    Output values returned:\n",
      "        [\"Speech stopped.\"]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import gradio as gr\n",
    "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from gradio_modal import Modal\n",
    "\n",
    "# Azure OpenAI 및 Cognitive Search 설정\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://team10-eighti.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "search_endpoint = os.getenv(\"SEARCH_ENDPOINT\", \"https://team10-eighti-search.search.windows.net\")\n",
    "search_key = os.getenv(\"SEARCH_KEY\", \"wnalAsW6FqKRHIR6S3sUZGzNH28Lf3sBOS2ubCZsZxAzSeA205k3\")\n",
    "search_index = os.getenv(\"SEARCH_INDEX_NAME\", \"sign-index\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"1BajXTI5Mp0tKrs46XFGuOWjSPXKzOZSKy8e6R3qha1SVQ4lz1PFJQQJ99ALACYeBjFXJ3w3AAABACOGgPvw\")\n",
    "\n",
    "# Azure Speech Service 설정 (한국어 음성 출력)\n",
    "speech_key = os.getenv(\"AZURE_SPEECH_KEY\", \"AwjVcsBAkpnrMNwkobsgJ4SSroO1GkAztrEIYp1JuMTcuKcfDR3wJQQJ99ALACYeBjFXJ3w3AAAYACOGZMDc\")\n",
    "speech_region = os.getenv(\"AZURE_SPEECH_REGION\", \"eastus\")\n",
    "speech_config = SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_synthesis_language = \"ko-KR\"  # 한국어 설정\n",
    "speech_config.speech_synthesis_voice_name = \"ko-KR-SunHiNeural\"  # 한국어 음성\n",
    "speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Initialize the prediction client\n",
    "ENDPOINT = \"https://team10eighticustomvision-prediction.cognitiveservices.azure.com/\"\n",
    "PREDICTION_KEY = \"9FRZbiwBubFIcSZ1k88tCTCskOAZwMMAMvnFLuVJ26tlU0V0fsqjJQQJ99ALACYeBjFXJ3w3AAAIACOGOj1S\"\n",
    "PROJECT_ID = \"4218ecac-688a-422b-9e14-2726b938f67c\"\n",
    "PUBLISHED_NAME = \"Iteration8\"\n",
    " \n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(endpoint=ENDPOINT, credentials=credentials)\n",
    "\n",
    "# Azure OpenAI 클라이언트 초기화\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# 음성 멈춤 기능을 위한 전역 변수\n",
    "is_speaking = False\n",
    "\n",
    "# 음성을 멈추는 함수\n",
    "def stop_speech():\n",
    "    global is_speaking\n",
    "    if is_speaking:\n",
    "        speech_synthesizer.stop_speaking_async()\n",
    "        is_speaking = False\n",
    "    return \"Speech stopped.\"\n",
    "\n",
    "# 채팅\n",
    "def chat_with_openai(user_input, chat_history):\n",
    "    # 수어가 있는 경우\n",
    "    try:\n",
    "        global is_speaking\n",
    "        # 대화 기록 포함 메시지 구성\n",
    "        messages = [{\"role\": \"system\", \"content\": \"너는 수화를 알려주는 전문가야\"}]\n",
    "        for user_msg, assistant_msg in chat_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Azure OpenAI API 호출\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{search_endpoint}\",\n",
    "                        \"index_name\": search_index,\n",
    "                        \"semantic_configuration\": \"sign-semantic\",\n",
    "                        \"query_type\": \"semantic\",\n",
    "                        \"fields_mapping\": {},\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": \"너는 수화를 알려주는 전문가야\",\n",
    "                        \"filter\": None,\n",
    "                        \"strictness\": 3,\n",
    "                        \"top_n_documents\": 5,\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{search_key}\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 응답 추출 및 대화 기록 업데이트\n",
    "        assistant_reply = completion.choices[0].message.content.replace(' [doc1]', '').strip()  # 속성 접근 방식으로 수정\n",
    "\n",
    "        chat_history.append((user_input, assistant_reply))  # 튜플 형태로 추가\n",
    "\n",
    "        # 출처와 관련된 내용 확인\n",
    "        citations = completion.choices[0].message.context['citations'][0]['content'].split('\\n')\n",
    "        video_url = citations[-2]\n",
    "        image_urls = citations[-3].split(' ')  # 이미지 URL이 여러 개일 수 있음\n",
    "\n",
    "        # Azure Speech Service로 응답 읽기 (텍스트를 한국어 음성으로 변환)\n",
    "        is_speaking = True\n",
    "        speech_synthesizer.speak_text_async(assistant_reply)\n",
    "\n",
    "        return chat_history, '', video_url, image_urls, gr.update(visible=True), gr.update(visible=False)\n",
    "\n",
    "    # 지문자로 대체하는 경우\n",
    "    except Exception as e:\n",
    "        # 오류 메시지 대체\n",
    "        fallback_message = \"수어로 확인하기 어려운 단어입니다. 지문자로 연습해보세요!\"\n",
    "        chat_history.append((user_input, fallback_message))\n",
    "\n",
    "        return chat_history, '', None, [], gr.update(visible=False), gr.update(visible=True)\n",
    "\n",
    "# Custom Vision\n",
    "def process_frame(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert frame to PIL Image\n",
    "    pil_image = Image.fromarray(frame)\n",
    "    \n",
    "    # Save to bytes for Azure API\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    pil_image.save(img_byte_arr, format='PNG')\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "    try:\n",
    "        # Get predictions from Azure Custom Vision\n",
    "        results = predictor.detect_image(PROJECT_ID, PUBLISHED_NAME, img_byte_arr)\n",
    "        \n",
    "        # Draw boxes on frame\n",
    "        annotated_frame = draw_boxes(frame, results.predictions)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return frame\n",
    "\n",
    "def draw_boxes(image, predictions):\n",
    "    \"\"\"Draw bounding boxes on the image based on predictions\"\"\"\n",
    "    img = image.copy()\n",
    "    for pred in predictions:\n",
    "        if pred.probability > 0.9 :\n",
    "            color = (255, 0, 0)\n",
    "            box = pred.bounding_box\n",
    "            left = int(box.left * img.shape[1])\n",
    "            top = int(box.top * img.shape[0])\n",
    "            width = int(box.width * img.shape[1])\n",
    "            height = int(box.height * img.shape[0])\n",
    "        \n",
    "        # Draw rectangle\n",
    "            cv2.rectangle(img, \n",
    "                        (left, top), \n",
    "                        (left + width, top + height), \n",
    "                        color, \n",
    "                        2)\n",
    "        \n",
    "        # Add label with confidence score\n",
    "            label = f\"{pred.tag_name}: {pred.probability:.2f}\"\n",
    "            cv2.putText(img, \n",
    "                        label, \n",
    "                        (left, top - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.5, \n",
    "                        color, \n",
    "                        2)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(label=\"Your Message\", placeholder=\"메시지를 입력하세요...\")\n",
    "            clear_button = gr.Button(\"Clear Chat\")\n",
    "            stop_button = gr.Button(\"Stop Speech\")\n",
    "        with gr.Column(visible=False) as column1:   # 기본적으로 숨김\n",
    "            video_display = gr.Video(label=\"수어 영상\")\n",
    "            image_display = gr.Gallery(label=\"수어 이미지\", columns=3)\n",
    "        with gr.Column(visible=False) as column2:   # 기본적으로 숨김\n",
    "            with gr.Row():\n",
    "                webcam_input = gr.Image(sources=\"webcam\", streaming=True, mirror_webcam=True, label=\"Webcam\")\n",
    "                webcam_output = gr.Image(label=\"Detected Objects\")\n",
    "            show_btn = gr.Button(\"힌트\")\n",
    "    with Modal(visible=False) as modal:  # 지문자 힌트 보여주기\n",
    "            gr.Textbox(\"이미지가 보여질 공간\")\n",
    "\n",
    "\n",
    "    # 대화 기록 저장\n",
    "    state = gr.State([])\n",
    "\n",
    "    # 이벤트 연결\n",
    "    webcam_input.stream(process_frame, inputs=webcam_input, outputs=webcam_output)\n",
    "    user_input.submit(chat_with_openai, [user_input, state], [chatbot, user_input, video_display, image_display, column1, column2])\n",
    "    clear_button.click(\n",
    "        lambda: ([], []),  # chatbot과 state를 모두 초기화\n",
    "        inputs=None,\n",
    "        outputs=[chatbot, state]  # chatbot과 state 모두 업데이트\n",
    "    )\n",
    "    stop_button.click(stop_speech)  # 음성을 멈추기\n",
    "    show_btn.click(lambda: Modal(visible=True), None, modal)  # 지문자 힌트 보여주기\n",
    "    \n",
    "# 실행\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
